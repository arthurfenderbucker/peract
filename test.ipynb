{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/peract/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.randn(1, 1, 10, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[3, 3, 3],\n",
      "          [0, 2, 1],\n",
      "          [2, 2, 2],\n",
      "          [2, 3, 3],\n",
      "          [3, 3, 3]],\n",
      "\n",
      "         [[1, 1, 2],\n",
      "          [3, 0, 0],\n",
      "          [0, 2, 2],\n",
      "          [2, 0, 1],\n",
      "          [1, 1, 0]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[6.5909e-01, 9.7190e-01, 1.9391e-01, 1.3816e-01],\n",
       "           [4.2687e-01, 5.4640e-01, 6.5528e-01, 8.1389e-01],\n",
       "           [1.7854e-01, 1.0000e+06, 9.0916e-01, 4.1194e-01],\n",
       "           [4.3824e-01, 5.0802e-01, 1.2147e-02, 3.3010e-01]],\n",
       "\n",
       "          [[6.5977e-01, 6.0427e-01, 7.7243e-01, 4.0838e-01],\n",
       "           [9.3267e-01, 6.2912e-01, 6.7900e-01, 3.6344e-01],\n",
       "           [1.2844e-01, 9.9407e-01, 3.3844e-02, 7.8095e-02],\n",
       "           [3.0516e-01, 8.9618e-01, 6.6241e-01, 9.4504e-01]],\n",
       "\n",
       "          [[1.0489e-01, 7.3050e-01, 7.6884e-01, 9.1267e-01],\n",
       "           [8.4482e-01, 3.6059e-01, 5.7230e-01, 4.4435e-01],\n",
       "           [9.5619e-01, 6.3366e-01, 1.0000e+06, 2.1029e-02],\n",
       "           [6.6485e-01, 3.7745e-02, 7.7088e-01, 1.0000e+06]],\n",
       "\n",
       "          [[3.1593e-02, 4.6744e-01, 1.6832e-01, 5.1431e-01],\n",
       "           [6.4559e-01, 6.9997e-01, 1.7685e-01, 6.7740e-01],\n",
       "           [4.6544e-01, 3.6428e-01, 7.5908e-01, 6.0302e-01],\n",
       "           [9.7668e-01, 8.5747e-01, 2.8905e-01, 1.0000e+06]]],\n",
       "\n",
       "\n",
       "         [[[4.6977e-01, 3.9407e-01, 8.1596e-01, 6.7436e-01],\n",
       "           [1.0350e-01, 8.7112e-01, 8.5796e-01, 1.2835e-01],\n",
       "           [7.0956e-01, 5.1948e-01, 1.0000e+06, 6.1437e-01],\n",
       "           [8.6024e-01, 7.8197e-01, 4.5657e-01, 8.7540e-01]],\n",
       "\n",
       "          [[3.2644e-01, 9.8250e-01, 8.3211e-01, 6.7209e-01],\n",
       "           [1.0000e+06, 4.2165e-01, 1.0000e+06, 7.0950e-01],\n",
       "           [1.3120e-01, 8.6004e-01, 4.8599e-02, 4.0537e-01],\n",
       "           [1.2178e-01, 7.6021e-01, 9.8988e-01, 8.8736e-02]],\n",
       "\n",
       "          [[7.2799e-01, 1.0000e+06, 8.0129e-01, 7.9108e-01],\n",
       "           [8.3566e-01, 3.3970e-01, 2.1893e-01, 5.4212e-01],\n",
       "           [5.8154e-01, 7.6882e-01, 9.9044e-01, 4.2953e-01],\n",
       "           [1.2781e-01, 7.0707e-01, 5.0903e-01, 5.4054e-01]],\n",
       "\n",
       "          [[1.0000e+06, 4.8460e-01, 8.1261e-02, 9.6170e-01],\n",
       "           [9.4811e-01, 1.8799e-01, 3.2923e-01, 4.6192e-01],\n",
       "           [1.4953e-01, 9.5548e-01, 7.9134e-01, 7.4724e-01],\n",
       "           [4.6897e-01, 9.1851e-01, 6.5762e-01, 7.7986e-01]]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor A and indices\n",
    "b, c, h, w, d = 1, 2, 4, 4, 4  # Adjust dimensions as needed\n",
    "A = torch.rand(b, c, h, w, d)  # Example tensor\n",
    "\n",
    "# Example indices with shape (b, c, 100, 3)\n",
    "# Assuming `indices` is the tensor you have, e.g.:\n",
    "indices = torch.randint(0, 4, (b, c, 5, 3))  # Example indices, adjust as needed\n",
    "\n",
    "print(indices)\n",
    "# Value x to set\n",
    "x = 999999\n",
    "\n",
    "# Generate indices for the b and c dimensions\n",
    "b_indices = torch.arange(b).view(b, 1, 1, 1).expand(-1, c, indices.shape[2], 1)\n",
    "c_indices = torch.arange(c).view(1, c, 1, 1).expand(b, -1, indices.shape[2], 1)\n",
    "\n",
    "# Use advanced indexing to set values\n",
    "# Flatten the last three dimensions in A to use with flat indices\n",
    "A_flat = A.view(b, c, -1)\n",
    "\n",
    "# Calculate flat indices for the last three dimensions\n",
    "flat_indices = indices[..., 0]*w*d + indices[..., 1]*d + indices[..., 2]\n",
    "\n",
    "# Set the values using the generated indices\n",
    "A_flat[b_indices, c_indices, flat_indices.unsqueeze(-1)] = x\n",
    "\n",
    "# Reshape A_flat back if needed (it's not actually necessary here, \n",
    "# since we're modifying A in place through its view)\n",
    "A = A_flat.view(b, c, h, w, d)\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3]) \n",
      " tensor([[[[5, 1, 7],\n",
      "          [9, 5, 5],\n",
      "          [5, 0, 2],\n",
      "          [6, 6, 0]]]]) \n",
      "\n",
      "tensor([[[[5, 9, 5, 6]]]]) tensor([[[[1, 5, 0, 6]]]]) tensor([[[[7, 5, 2, 0]]]])\n",
      "tensor([[[[3.2964, 3.1179, 2.7908, 2.7488]]]])\n",
      "tensor([[[[ 0.2395, -0.0970,  0.8501,  0.6692]]]])\n",
      "[tensor(3.2964), tensor(3.1179), tensor(2.7908), tensor(2.7488)]\n",
      "tensor(3.2964)\n",
      "tensor(3.1179)\n",
      "tensor(2.7908)\n",
      "tensor(2.7488)\n"
     ]
    }
   ],
   "source": [
    "def _topk_3d(tensor_orig, k=100):\n",
    "    b, c, d, h, w = tensor_orig.shape  # c will be one\n",
    "    idxs = torch.topk(tensor_orig.view(b, c, -1), k, dim=-1).indices\n",
    "    indices = torch.cat([((idxs // h) // d), (idxs // h) % w, idxs % w], 1).transpose(1, 2).view(b, c, k, 3)\n",
    "    return indices\n",
    "\n",
    "\n",
    "top4 = _topk_3d(a, 4)\n",
    "print(top4.shape,\"\\n\",top4,\"\\n\")\n",
    "\n",
    "\n",
    "b = torch.arange(a.size(0)).unsqueeze(1).unsqueeze(2)\n",
    "c = torch.arange(a.size(1)).unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "print(top4[b,c,:,0],top4[b,c,:,1],top4[b,c,:,2])\n",
    "\n",
    "# retreive the top 4 indices\n",
    "print(a[b,c,top4[b,c,:,0],top4[b,c,:,1],top4[b,c,:,2]])\n",
    "\n",
    "\n",
    "print(a[b,c,top4[b,c,:,2],top4[b,c,:,1],top4[b,c,:,0]])\n",
    "\n",
    "print([a[0,0,top4[0,0,i,0],top4[0,0,i,1],top4[0,0,i,2]] for i in range(4)])\n",
    "\n",
    "b = a[:]\n",
    "for i in range(4):\n",
    "    print(b.max())\n",
    "    b =b[b!=b.max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.randn(1, 3, 6, 15, 3)\n",
    "b, c, d, h, w = a.shape \n",
    "n = b*c*d*h*w\n",
    "a = torch.arange(n).reshape(a.shape)\n",
    "((n-1)%(h*w))%w\n",
    "((n-1)%(d*h*w))%h\n",
    "((n-1)%(c*d*h*w))%d\n",
    "\n",
    "((n-1)%(b*c*d*h*w))%c\n",
    "\n",
    "(n-1)%w\n",
    "\n",
    "((n-1)//c)%h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ((n-1)//(h*w))%h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original indices: [0, 0, 2, 5, 14]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_original_indices(flat_index, shape):\n",
    "    \"\"\"\n",
    "    Retrieve the original multidimensional indices of an element in an n-dimensional tensor\n",
    "    given its index in the flattened version.\n",
    "\n",
    "    Parameters:\n",
    "    - flat_index: An integer representing the index of the element in the flattened tensor.\n",
    "    - shape: The original shape of the tensor as a tuple or torch.Size object.\n",
    "\n",
    "    Returns:\n",
    "    - A list of indices representing the position of the element in the original tensor.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "\n",
    "    # Calculate the cumulative product of the tensor dimensions in reverse order\n",
    "    # This will be used to determine the contribution of each dimension to the flat index\n",
    "    cumprod = torch.tensor(shape).flip(dims=[0]).cumprod(0).flip(dims=[0])\n",
    "\n",
    "    # Iterate through dimensions to compute the indices\n",
    "    for i in range(len(shape)):\n",
    "        if i == 0:\n",
    "            # For the first dimension, simply divide by the cumulative product of the remaining dimensions\n",
    "            idx = flat_index // cumprod[i]\n",
    "        else:\n",
    "            # For subsequent dimensions, calculate the remainder from the previous division\n",
    "            # and divide by the cumulative product of the remaining dimensions\n",
    "            idx = (flat_index % cumprod[i-1]) // cumprod[i]\n",
    "        indices.append(idx.item())\n",
    "\n",
    "    return indices\n",
    "\n",
    "# Example usage\n",
    "a = torch.randn(1, 3, 6, 15, 3)\n",
    "b, c, d, h, w = a.shape \n",
    "n = b*c*d*h*w\n",
    "a = torch.arange(n).reshape(a.shape)\n",
    "# flat_index = torch.tensor([123])  # Example flat index\n",
    "flat_index = a.max()-2\n",
    "\n",
    "original_indices = get_original_indices(flat_index, a.shape)\n",
    "print(\"Original indices:\", original_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 15, 3])\n",
      "torch.Size([1, 1, 5])\n",
      "torch.Size([1, 4, 5])\n",
      "torch.Size([1, 5, 4]) \n",
      " tensor([[[ 2,  5, 14,  2],\n",
      "         [ 2,  4, 13,  1],\n",
      "         [ 2,  3, 12,  0],\n",
      "         [ 2,  2, 11,  2],\n",
      "         [ 2,  1, 10,  1]]]) \n",
      "\n",
      "tensor([[[809, 760, 711, 665, 616]]])\n",
      "tensor(809)\n",
      "tensor(808)\n",
      "tensor(807)\n",
      "tensor(806)\n",
      "tensor(805)\n"
     ]
    }
   ],
   "source": [
    "def _topk_4d(tensor_orig, k=100):\n",
    "    b, c, d, h, w = tensor_orig.shape  # c will be one\n",
    "    print( tensor_orig.shape)\n",
    "    idxs = torch.topk(tensor_orig.view(b, -1), k, dim=-1).indices\n",
    "    idxs = idxs.unsqueeze(1)\n",
    "    print(idxs.shape)\n",
    "\n",
    "    indices = torch.cat([(idxs // (h*d*w)), (idxs%(c*d*h*w))%d, (idxs %(d*h*w))%h, idxs % w], 1)\n",
    "    print(indices.shape)\n",
    "    indices = indices.transpose(1, 2).view(b, k, 4)\n",
    "    return indices\n",
    "\n",
    "\n",
    "top4 = _topk_4d(a, 5)\n",
    "print(top4.shape,\"\\n\",top4,\"\\n\")\n",
    "b = torch.arange(a.size(0)).unsqueeze(1)\n",
    "print(a[b,top4[b,:,0],top4[b,:,1],top4[b,:,2], top4[b,:,3]])\n",
    "\n",
    "b = a[:]\n",
    "for i in range(5):\n",
    "    print(b.max())\n",
    "    b =b[b!=b.max()]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
